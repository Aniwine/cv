{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 示例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mmyolo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from mmengine.model import BaseModel\n",
    "from mmengine.evaluator import BaseMetric\n",
    "from mmengine.registry import MODELS, DATASETS, METRICS\n",
    "\n",
    "\n",
    "@MODELS.register_module()\n",
    "class MyAwesomeModel(BaseModel):\n",
    "    def __init__(self, layers=4, activation='relu') -> None:\n",
    "        super().__init__()\n",
    "        if activation == 'relu':\n",
    "            act_type = nn.ReLU\n",
    "        elif activation == 'silu':\n",
    "            act_type = nn.SiLU\n",
    "        elif activation == 'none':\n",
    "            act_type = nn.Identity\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        sequence = [nn.Linear(2, 64), act_type()]\n",
    "        for _ in range(layers-1):\n",
    "            sequence.extend([nn.Linear(64, 64), act_type()])\n",
    "        self.mlp = nn.Sequential(*sequence)\n",
    "        self.classifier = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, data, labels, mode):\n",
    "        x = self.mlp(data)\n",
    "        x = self.classifier(x)\n",
    "        if mode == 'tensor':\n",
    "            return x\n",
    "        elif mode == 'predict':\n",
    "            return F.softmax(x, dim=1), labels\n",
    "        elif mode == 'loss':\n",
    "            return {'loss': F.cross_entropy(x, labels)}\n",
    "\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, is_train, size):\n",
    "        self.is_train = is_train\n",
    "        if self.is_train:\n",
    "            torch.manual_seed(0)\n",
    "            self.labels = torch.randint(0, 2, (size,))\n",
    "        else:\n",
    "            torch.manual_seed(3407)\n",
    "            self.labels = torch.randint(0, 2, (size,))\n",
    "        r = 3 * (self.labels+1) + torch.randn(self.labels.shape)\n",
    "        theta = torch.rand(self.labels.shape) * 2 * torch.pi\n",
    "        self.data = torch.vstack([r*torch.cos(theta), r*torch.sin(theta)]).T\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "@METRICS.register_module()\n",
    "class Accuracy(BaseMetric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def process(self, data_batch, data_samples):\n",
    "        score, gt = data_samples\n",
    "        self.results.append({\n",
    "            'batch_size': len(gt),\n",
    "            'correct': (score.argmax(dim=1) == gt).sum().cpu(),\n",
    "        })\n",
    "\n",
    "    def compute_metrics(self, results):\n",
    "        total_correct = sum(r['correct'] for r in results)\n",
    "        total_size = sum(r['batch_size'] for r in results)\n",
    "        return dict(accuracy=100*total_correct/total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Your CUDA code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/11 08:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:39:04) [GCC 10.3.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1889739447\n",
      "    GPU 0,1: GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 10.2, V10.2.8\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.12.1+cu102\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu102\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.2\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    backend: nccl\n",
      "    mp_cfg: {'mp_start_method': 'fork'}\n",
      "    seed: 1889739447\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "08/11 08:09:29 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Dataset MyDataset has no metainfo. ``dataset_meta`` in visualizer will be None.\n",
      "08/11 08:09:29 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class Accuracy.\n",
      "08/11 08:09:29 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Dataset MyDataset has no metainfo. ``dataset_meta`` in evaluator, metric and visualizer will be None.\n",
      "08/11 08:09:29 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/11 08:09:29 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /volume/opemmmlab/mmengine/exp/my_awesome_model.\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10/157]  lr: 1.0000e-03  eta: 0:00:36  time: 0.0233  data_time: 0.0107  memory: 0  loss: 0.6685\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 20/157]  lr: 1.0000e-03  eta: 0:00:19  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.6586\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 30/157]  lr: 1.0000e-03  eta: 0:00:14  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.6233\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 40/157]  lr: 1.0000e-03  eta: 0:00:11  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.5936\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 50/157]  lr: 1.0000e-03  eta: 0:00:09  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.5538\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 60/157]  lr: 1.0000e-03  eta: 0:00:08  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.5048\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 70/157]  lr: 1.0000e-03  eta: 0:00:07  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.4735\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 80/157]  lr: 1.0000e-03  eta: 0:00:07  time: 0.0022  data_time: 0.0003  memory: 0  loss: 0.4081\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 90/157]  lr: 1.0000e-03  eta: 0:00:06  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.3439\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/157]  lr: 1.0000e-03  eta: 0:00:06  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.3089\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][110/157]  lr: 1.0000e-03  eta: 0:00:06  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2943\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][120/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2329\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][130/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2434\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][140/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2315\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][150/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2329\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 10/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0095  data_time: 0.0074  memory: 0  loss: 0.2000\n",
      "08/11 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 20/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.1927\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 30/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2076\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 40/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1696\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 50/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.1967\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 60/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.2016\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 70/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1932\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 80/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1854\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 90/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2012\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2177\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][110/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1793\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][120/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2004\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][130/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.1871\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][140/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1853\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][150/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1971\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][1/1]    accuracy: 93.4000  data_time: 0.1607  time: 0.1620\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 10/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0096  data_time: 0.0075  memory: 0  loss: 0.1803\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 20/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.1852\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 30/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0022  data_time: 0.0003  memory: 0  loss: 0.1992\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 40/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1822\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 50/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1808\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 60/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2257\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 70/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1535\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 80/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0022  data_time: 0.0003  memory: 0  loss: 0.1649\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 90/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0022  data_time: 0.0003  memory: 0  loss: 0.1992\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1519\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][110/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1998\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][120/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1817\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][130/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.2002\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][140/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2091\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][150/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1992\n",
      "08/11 08:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][1/1]    accuracy: 93.7000  data_time: 0.1602  time: 0.1615\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 10/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0096  data_time: 0.0074  memory: 0  loss: 0.1553\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 20/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.2000\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 30/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1817\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 40/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2217\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 50/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1810\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 60/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0102  data_time: 0.0003  memory: 0  loss: 0.2188\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 70/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2036\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 80/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1620\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 90/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1792\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1939\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][110/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1452\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][120/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1834\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][130/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1795\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][140/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2002\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][150/157]  lr: 1.0000e-03  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2072\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][1/1]    accuracy: 92.9000  data_time: 0.1183  time: 0.1196\n",
      "08/11 08:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 10/157]  lr: 1.0000e-04  eta: 0:00:03  time: 0.0097  data_time: 0.0075  memory: 0  loss: 0.2163\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 20/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0025  data_time: 0.0004  memory: 0  loss: 0.1544\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 30/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2010\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 40/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2185\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 50/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1721\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 60/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1536\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 70/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1690\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 80/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1779\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 90/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2116\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1658\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][110/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1605\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][120/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1699\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][130/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1761\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][140/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1659\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][150/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1809\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][1/1]    accuracy: 93.9000  data_time: 0.0771  time: 0.0785\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 10/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0097  data_time: 0.0075  memory: 0  loss: 0.1940\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 20/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.1980\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 30/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1818\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 40/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1694\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 50/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1849\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 60/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1871\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 70/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1888\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 80/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1520\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 90/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1731\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][100/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1691\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][110/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1881\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][120/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1517\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][130/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1853\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][140/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2020\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][150/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1685\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][1/1]    accuracy: 94.2000  data_time: 0.0774  time: 0.0787\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 10/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0097  data_time: 0.0076  memory: 0  loss: 0.1711\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 20/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.1655\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 30/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1840\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 40/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1606\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 50/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1814\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 60/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1907\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 70/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1779\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 80/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1999\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 90/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2121\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][100/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1749\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][110/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1737\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][120/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1512\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][130/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1773\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][140/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1931\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][150/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0022  data_time: 0.0003  memory: 0  loss: 0.1662\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 7 epochs\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][1/1]    accuracy: 94.3000  data_time: 0.0775  time: 0.0788\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 10/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0098  data_time: 0.0075  memory: 0  loss: 0.1573\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 20/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0026  data_time: 0.0004  memory: 0  loss: 0.1861\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 30/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1653\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 40/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1931\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 50/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1911\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 60/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1816\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 70/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.2042\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 80/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1811\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 90/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1857\n",
      "08/11 08:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][100/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1948\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][110/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1520\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][120/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1782\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][130/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1956\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][140/157]  lr: 1.0000e-04  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1486\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][150/157]  lr: 1.0000e-04  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1679\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][1/1]    accuracy: 94.4000  data_time: 0.0787  time: 0.0800\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 10/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0097  data_time: 0.0075  memory: 0  loss: 0.1718\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 20/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.1897\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 30/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1502\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 40/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1977\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 50/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1653\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 60/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1712\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 70/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2010\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 80/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2030\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 90/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1962\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][100/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1571\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][110/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1888\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][120/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1538\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][130/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1648\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][140/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1945\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][150/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1722\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][1/1]    accuracy: 94.4000  data_time: 0.0785  time: 0.0798\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 10/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0097  data_time: 0.0076  memory: 0  loss: 0.1722\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 20/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0004  memory: 0  loss: 0.2041\n",
      "08/11 08:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 30/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1642\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 40/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1705\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 50/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1672\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 60/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1889\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 70/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1681\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 80/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2126\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 90/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1844\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][100/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1720\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][110/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.1548\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][120/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1424\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][130/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1796\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][140/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1942\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][150/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1934\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230811_080928\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
      "08/11 08:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][1/1]    accuracy: 94.5000  data_time: 0.0773  time: 0.0786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyAwesomeModel(\n",
       "  (data_preprocessor): BaseDataPreprocessor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torch.optim import Adam\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "\n",
    "runner = Runner(\n",
    "    # 你的模型\n",
    "    model=MyAwesomeModel(\n",
    "        layers=2,\n",
    "        activation='relu'),\n",
    "    # 模型检查点、日志等都将存储在工作路径中\n",
    "    work_dir='exp/my_awesome_model',\n",
    "\n",
    "    # 训练所用数据\n",
    "    train_dataloader=DataLoader(\n",
    "        dataset=MyDataset(\n",
    "            is_train=True,\n",
    "            size=10000),\n",
    "        shuffle=True,\n",
    "        collate_fn=default_collate,\n",
    "        batch_size=64,\n",
    "        pin_memory=True,\n",
    "        num_workers=2),\n",
    "    # 训练相关配置\n",
    "    train_cfg=dict(\n",
    "        by_epoch=True,   # 根据 epoch 计数而非 iteration\n",
    "        max_epochs=10,\n",
    "        val_begin=2,     # 从第 2 个 epoch 开始验证\n",
    "        val_interval=1), # 每隔 1 个 epoch 进行一次验证\n",
    "\n",
    "    # 优化器封装，MMEngine 中的新概念，提供更丰富的优化选择。\n",
    "    # 通常使用默认即可，可缺省。有特殊需求可查阅文档更换，如\n",
    "    # 'AmpOptimWrapper' 开启混合精度训练\n",
    "    optim_wrapper=dict(\n",
    "        optimizer=dict(\n",
    "            type=Adam,\n",
    "            lr=0.001)),\n",
    "    # 参数调度器，用于在训练中调整学习率/动量等参数\n",
    "    param_scheduler=dict(\n",
    "        type='MultiStepLR',\n",
    "        by_epoch=True,\n",
    "        milestones=[4, 8],\n",
    "        gamma=0.1),\n",
    "\n",
    "    # 验证所用数据\n",
    "    val_dataloader=DataLoader(\n",
    "        dataset=MyDataset(\n",
    "            is_train=False,\n",
    "            size=1000),\n",
    "        shuffle=False,\n",
    "        collate_fn=default_collate,\n",
    "        batch_size=1000,\n",
    "        pin_memory=True,\n",
    "        num_workers=2),\n",
    "    # 验证相关配置，通常为空即可\n",
    "    val_cfg=dict(),\n",
    "    # 验证指标与验证器封装，可自由实现与配置\n",
    "    val_evaluator=dict(type=Accuracy),\n",
    "\n",
    "    # 以下为其他进阶配置，无特殊需要时尽量缺省\n",
    "    # 钩子属于进阶用法，如无特殊需要，尽量缺省\n",
    "    default_hooks=dict(\n",
    "        # 最常用的默认钩子，可修改保存 checkpoint 的间隔\n",
    "        checkpoint=dict(type='CheckpointHook', interval=1)),\n",
    "\n",
    "    # `luancher` 与 `env_cfg` 共同构成分布式训练环境配置\n",
    "    launcher='none',\n",
    "    env_cfg=dict(\n",
    "        cudnn_benchmark=False,   # 是否使用 cudnn_benchmark\n",
    "        backend='nccl',   # 分布式通信后端\n",
    "        mp_cfg=dict(mp_start_method='fork')),  # 多进程设置\n",
    "    log_level='INFO',\n",
    "\n",
    "    # 加载权重的路径 (None 表示不加载)\n",
    "    load_from=None,\n",
    "    # 从加载的权重文件中恢复训练\n",
    "    resume=False\n",
    ")\n",
    "\n",
    "# 开始训练你的模型吧\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 从配置文件读取runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/11 08:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:39:04) [GCC 10.3.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1795255611\n",
      "    GPU 0,1: GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 10.2, V10.2.8\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.12.1+cu102\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu102\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.2\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    backend: nccl\n",
      "    mp_cfg: {'mp_start_method': 'fork'}\n",
      "    seed: 1795255611\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/11 08:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "model = dict(type='MyAwesomeModel', layers=2, activation='relu')\n",
      "work_dir = 'exp/my_awesome_model'\n",
      "train_dataloader = dict(\n",
      "    dataset=dict(type='MyDataset', is_train=True, size=10000),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=64,\n",
      "    pin_memory=True,\n",
      "    num_workers=2)\n",
      "train_cfg = dict(by_epoch=True, max_epochs=10, val_begin=2, val_interval=1)\n",
      "optim_wrapper = dict(optimizer=dict(type='Adam', lr=0.001))\n",
      "param_scheduler = dict(\n",
      "    type='MultiStepLR', by_epoch=True, milestones=[\n",
      "        4,\n",
      "        8,\n",
      "    ], gamma=0.1)\n",
      "val_dataloader = dict(\n",
      "    dataset=dict(type='MyDataset', is_train=False, size=1000),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=1000,\n",
      "    pin_memory=True,\n",
      "    num_workers=2)\n",
      "val_cfg = dict()\n",
      "val_evaluator = dict(type='Accuracy')\n",
      "default_hooks = dict(checkpoint=dict(type='CheckpointHook', interval=1))\n",
      "launcher = 'none'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False, backend='nccl', mp_cfg=dict(mp_start_method='fork'))\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume = False\n",
      "\n",
      "08/11 08:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/11 08:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "08/11 08:13:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Dataset MyDataset has no metainfo. ``dataset_meta`` in visualizer will be None.\n",
      "08/11 08:13:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class Accuracy.\n",
      "08/11 08:13:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Dataset MyDataset has no metainfo. ``dataset_meta`` in evaluator, metric and visualizer will be None.\n",
      "08/11 08:13:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/11 08:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /volume/opemmmlab/mmengine/exp/my_awesome_model.\n",
      "08/11 08:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10/157]  lr: 1.0000e-03  eta: 0:00:16  time: 0.0107  data_time: 0.0085  memory: 0  loss: 0.6527\n",
      "08/11 08:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 20/157]  lr: 1.0000e-03  eta: 0:00:10  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.6070\n",
      "08/11 08:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 30/157]  lr: 1.0000e-03  eta: 0:00:07  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.5606\n",
      "08/11 08:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 40/157]  lr: 1.0000e-03  eta: 0:00:06  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.5448\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 50/157]  lr: 1.0000e-03  eta: 0:00:06  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.5076\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 60/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0022  data_time: 0.0003  memory: 0  loss: 0.4389\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 70/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0022  data_time: 0.0003  memory: 0  loss: 0.4044\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 80/157]  lr: 1.0000e-03  eta: 0:00:05  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.3465\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 90/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.3247\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2812\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][110/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2520\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][120/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2432\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][130/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2207\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][140/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2222\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][150/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2137\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 10/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0098  data_time: 0.0077  memory: 0  loss: 0.2094\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 20/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0025  data_time: 0.0004  memory: 0  loss: 0.1996\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 30/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.2137\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 40/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.2135\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 50/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1932\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 60/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1875\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 70/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2043\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 80/157]  lr: 1.0000e-03  eta: 0:00:04  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1776\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 90/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1740\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2041\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][110/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1729\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][120/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1871\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][130/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1815\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][140/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0002  memory: 0  loss: 0.1670\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][150/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2150\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "08/11 08:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][1/1]    accuracy: 93.3000  data_time: 0.0778  time: 0.0791\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 10/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0098  data_time: 0.0076  memory: 0  loss: 0.1830\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 20/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.2087\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 30/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1920\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 40/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.1907\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 50/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2142\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 60/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1789\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 70/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2060\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 80/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1696\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 90/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0002  memory: 0  loss: 0.2417\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1825\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][110/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1792\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][120/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1580\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][130/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2080\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][140/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.1658\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][150/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1709\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][1/1]    accuracy: 93.8000  data_time: 0.0780  time: 0.0793\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 10/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0098  data_time: 0.0076  memory: 0  loss: 0.1860\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 20/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2086\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 30/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1953\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 40/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1778\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 50/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2164\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 60/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1787\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 70/157]  lr: 1.0000e-03  eta: 0:00:03  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.2367\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 80/157]  lr: 1.0000e-03  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1658\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 90/157]  lr: 1.0000e-03  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1562\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/157]  lr: 1.0000e-03  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1932\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][110/157]  lr: 1.0000e-03  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1707\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][120/157]  lr: 1.0000e-03  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1745\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][130/157]  lr: 1.0000e-03  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1791\n",
      "08/11 08:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][140/157]  lr: 1.0000e-03  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1818\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][150/157]  lr: 1.0000e-03  eta: 0:00:02  time: 0.0022  data_time: 0.0003  memory: 0  loss: 0.1742\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][1/1]    accuracy: 93.4000  data_time: 0.0782  time: 0.0795\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 10/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0097  data_time: 0.0076  memory: 0  loss: 0.1795\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 20/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.1648\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 30/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1719\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 40/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1507\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 50/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1818\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 60/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1864\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 70/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1756\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 80/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1793\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 90/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1984\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1729\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][110/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1798\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][120/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2082\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][130/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1911\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][140/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1772\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][150/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1683\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][1/1]    accuracy: 94.0000  data_time: 0.0783  time: 0.0796\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 10/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0098  data_time: 0.0076  memory: 0  loss: 0.1783\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 20/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0025  data_time: 0.0004  memory: 0  loss: 0.1857\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 30/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1410\n",
      "08/11 08:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 40/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2027\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 50/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1885\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 60/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1877\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 70/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1907\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 80/157]  lr: 1.0000e-04  eta: 0:00:02  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1755\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 90/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1657\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][100/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1940\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][110/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1798\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][120/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1459\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][130/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1796\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][140/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1779\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][150/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.1898\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][1/1]    accuracy: 94.0000  data_time: 0.0784  time: 0.0798\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 10/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0098  data_time: 0.0076  memory: 0  loss: 0.1546\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 20/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0004  memory: 0  loss: 0.1902\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 30/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.2311\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 40/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.1726\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 50/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1687\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 60/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1602\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 70/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1640\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 80/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1813\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 90/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1827\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][100/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1982\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][110/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1682\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][120/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1631\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][130/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1549\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][140/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1974\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][150/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1836\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 7 epochs\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][1/1]    accuracy: 93.9000  data_time: 0.0779  time: 0.0792\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 10/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0097  data_time: 0.0076  memory: 0  loss: 0.1826\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 20/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.1853\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 30/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1585\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 40/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.2057\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 50/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1872\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 60/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1801\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 70/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1926\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 80/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1685\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 90/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1755\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][100/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1813\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][110/157]  lr: 1.0000e-04  eta: 0:00:01  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1731\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][120/157]  lr: 1.0000e-04  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1629\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][130/157]  lr: 1.0000e-04  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1423\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][140/157]  lr: 1.0000e-04  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2282\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][150/157]  lr: 1.0000e-04  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1623\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][1/1]    accuracy: 94.3000  data_time: 0.0775  time: 0.0788\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 10/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0097  data_time: 0.0075  memory: 0  loss: 0.1440\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 20/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.1579\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 30/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2108\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 40/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1930\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 50/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1733\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 60/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1560\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 70/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1715\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 80/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1865\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 90/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1757\n",
      "08/11 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][100/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2103\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][110/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1938\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][120/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1658\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][130/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1857\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][140/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1740\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][150/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1869\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][1/1]    accuracy: 94.1000  data_time: 0.0779  time: 0.0792\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 10/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0097  data_time: 0.0076  memory: 0  loss: 0.1535\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 20/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0004  memory: 0  loss: 0.1941\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 30/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1666\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 40/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.1950\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 50/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0026  data_time: 0.0003  memory: 0  loss: 0.1750\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 60/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1701\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 70/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1832\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 80/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.2086\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 90/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1484\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][100/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0023  data_time: 0.0003  memory: 0  loss: 0.1699\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][110/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1860\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][120/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.2023\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][130/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0003  memory: 0  loss: 0.1679\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][140/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0025  data_time: 0.0002  memory: 0  loss: 0.1429\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][150/157]  lr: 1.0000e-05  eta: 0:00:00  time: 0.0024  data_time: 0.0003  memory: 0  loss: 0.1841\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: example_config_20230811_081305\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
      "08/11 08:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][1/1]    accuracy: 94.1000  data_time: 0.0781  time: 0.0795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyAwesomeModel(\n",
       "  (data_preprocessor): BaseDataPreprocessor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "config=Config.fromfile('/volume/opemmmlab/mmengine/config/example_config.py')\n",
    "runner=Runner.from_cfg(config)\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmyolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
