{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 构建dataset和dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def create_palette(csv_file):\n",
    "    color2class={}\n",
    "    #newline控制读取内容换行符的处理方式，''表示替换为自适应系统；None表示不做处理；'\\n'表示全部替换为\\n\n",
    "    with open(csv_file,newline='') as f: \n",
    "    #csv.DictReader表示读取每一行都为一个字典，字典的键为第一行内容\n",
    "        reader=csv.DictReader(f)\n",
    "        for idx,item in enumerate(reader):\n",
    "            class_idx,color=idx,(int(item['r']),int(item['g']),int(item['b']))\n",
    "            color2class[color]=class_idx\n",
    "    return color2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(64, 128, 64): 0,\n",
       " (192, 0, 128): 1,\n",
       " (0, 128, 192): 2,\n",
       " (0, 128, 64): 3,\n",
       " (128, 0, 0): 4,\n",
       " (64, 0, 128): 5,\n",
       " (64, 0, 192): 6,\n",
       " (192, 128, 64): 7,\n",
       " (192, 192, 128): 8,\n",
       " (64, 64, 128): 9,\n",
       " (128, 0, 192): 10,\n",
       " (192, 0, 64): 11,\n",
       " (128, 128, 64): 12,\n",
       " (192, 0, 192): 13,\n",
       " (128, 64, 64): 14,\n",
       " (64, 192, 128): 15,\n",
       " (64, 64, 0): 16,\n",
       " (128, 64, 128): 17,\n",
       " (128, 128, 192): 18,\n",
       " (0, 0, 192): 19,\n",
       " (192, 128, 128): 20,\n",
       " (128, 128, 128): 21,\n",
       " (64, 128, 192): 22,\n",
       " (0, 0, 64): 23,\n",
       " (0, 64, 64): 24,\n",
       " (192, 64, 128): 25,\n",
       " (128, 128, 0): 26,\n",
       " (192, 128, 192): 27,\n",
       " (64, 0, 64): 28,\n",
       " (192, 192, 0): 29,\n",
       " (0, 0, 0): 30,\n",
       " (64, 192, 0): 31}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color2class=create_palette(r\"/volume/opemmmlab/mmengine/data/CamVid/class_dict.csv\")\n",
    "color2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class CamVid(VisionDataset):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 img_folder,\n",
    "                 mask_folder,\n",
    "                 transform=None,\n",
    "                 target_transform=None):\n",
    "        super().__init__(root,transform=transform,target_transform=target_transform)\n",
    "        self.img_folder=img_folder\n",
    "        self.mask_folder=mask_folder\n",
    "        self.images=list(sorted(os.listdir(os.path.join(root,img_folder))))\n",
    "        self.masks=list(sorted(os.listdir(os.path.join(root,mask_folder))))\n",
    "        self.color_2_class=create_palette(os.path.join(root,'class_dict.csv'))\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img_path=os.path.join(self.root,self.img_folder,self.images[index])\n",
    "        mask_path=os.path.join(self.root,self.mask_folder,self.masks[index])\n",
    "\n",
    "        img=Image.open(img_path).convert(\"RGB\")\n",
    "        mask=Image.open(mask_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img=self.transform(img)\n",
    "\n",
    "        #生成标签图\n",
    "        mask=np.array(mask)\n",
    "        mask=mask[:,:,0]*256**2+mask[:,:,1]*256+mask[:,:,2]\n",
    "\n",
    "        label=np.zeros_like(mask,np.int64)\n",
    "        for color,class_idx in self.color_2_class.items():\n",
    "            color=color[0]*256**2+color[1]*256+color[2]\n",
    "            label[mask==color]=class_idx\n",
    "\n",
    "        if self.target_transform:\n",
    "            label=self.target_transform(label)\n",
    "\n",
    "        data_samples=dict(labels=label,img_path=img_path,mask_path=mask_path)\n",
    "\n",
    "        return img,data_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "norm_cfg=dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(**norm_cfg)\n",
    "])\n",
    "\n",
    "target_transforms=transforms.Lambda(lambda x:torch.tensor(np.array(x),dtype=torch.long))\n",
    "\n",
    "train_set=CamVid(\n",
    "    './data/CamVid/',\n",
    "    img_folder='train',\n",
    "    mask_folder='train_labels',\n",
    "    transform=transform,\n",
    "    target_transform=target_transforms\n",
    ")\n",
    "val_set=CamVid(\n",
    "    './data/CamVid/',\n",
    "    img_folder='val',\n",
    "    mask_folder='val_labels',\n",
    "    transform=transform,\n",
    "    target_transform=target_transforms\n",
    ")\n",
    "\n",
    "train_dataloader=dict(\n",
    "    batch_size=3,\n",
    "    dataset=train_set,\n",
    "    sampler=dict(type=\"DefaultSampler\",shuffle=True),\n",
    "    collate_fn=dict(type=\"default_collate\")\n",
    ")\n",
    "\n",
    "val_dataloader=dict(\n",
    "    batch_size=1,\n",
    "    dataset=val_set,\n",
    "    sampler=dict(type=\"DefaultSampler\",shuffle=False),\n",
    "    collate_fn=dict(type=\"default_collate\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 构建分割模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from mmengine.model import BaseModel\n",
    "\n",
    "class MMDeeplabV3(BaseModel):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        self.deeplab=deeplabv3_resnet50()\n",
    "        self.deeplab.classifier[4]=torch.nn.Conv2d(\n",
    "            256, num_classes, kernel_size=(1, 1), stride=(1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self,imgs,data_samples=None,mode='tensor'):\n",
    "        x=self.deeplab(imgs)['out']\n",
    "        if mode=='loss':\n",
    "            return {'loss':F.cross_entropy(x,data_samples['labels'])}\n",
    "        elif mode=='predict':\n",
    "            return x,data_samples\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 定义IOU算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.evaluator import BaseMetric\n",
    "\n",
    "class IoU(BaseMetric):\n",
    "    def process(self,data_batch,data_samples):\n",
    "        #复习一下：pytorch的dataloader有如下作用，从数据集中的getitem函数出来几项，那么dataloader出来的\n",
    "        #也是相同项数，且每一项里都是bs个子项，如果是字典则键名也不变\n",
    "        #错啦错啦，这里算子的data_samples是模型的预测输出，只不过模型预测输出包含了gt\n",
    "        #实际上data_batch才是从dataloader出来的数据源\n",
    "        preds,labels=data_samples[0],data_samples[1]['labels']\n",
    "        #preds:bs*c*h*w,labels:bs*h*w\n",
    "        preds=torch.argmax(preds,dim=1)\n",
    "        insection=(preds==labels).sum()\n",
    "        union=torch.logical_or(preds,labels).sum()\n",
    "        iou=(insection/union).cpu()#注意这里计算的是一个bs所有图像的交并比\n",
    "        self.results.append(dict(batch_size=len(labels),iou=iou*len(labels)))\n",
    "    \n",
    "    #注意这里和我理解的一张图计算IoU不一样\n",
    "    def compute_metrics(self,results):\n",
    "        total_iou=sum([result['iou'] for result in results])\n",
    "        total_imgs=sum([result['batch_size'] for result in results])\n",
    "        return dict(iou=total_iou/total_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 定义可视化钩子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.hooks import Hook\n",
    "import cv2\n",
    "import shutil\n",
    "import os.path as osp\n",
    "\n",
    "class SegVisHook(Hook):\n",
    "    def __init__(self,data_root,vis_num=1):\n",
    "        super().__init__()\n",
    "        self.palette=create_palette(osp.join(data_root,'class_dict.csv'))\n",
    "        self.vis_num=vis_num\n",
    "        self.data_root=data_root\n",
    "\n",
    "    def after_val_iter(self,\n",
    "                       runner,\n",
    "                       batch_idx:int,\n",
    "                       data_batch=None,\n",
    "                       outputs=None):\n",
    "        if batch_idx>self.vis_num:\n",
    "            return\n",
    "        \n",
    "        #取出预测数据\n",
    "        preds,data_samples=outputs\n",
    "        img_paths,mask_paths=data_samples['img_path'],data_samples['mask_path']\n",
    "        _,C,H,W=preds.shape\n",
    "        #将三通道的预测图转为单通道，值表示每个像素点所属类别\n",
    "        preds=torch.argmax(preds,dim=1)\n",
    "        for idx,(pred,img_path,mask_path) in enumerate(zip(preds,img_paths,mask_paths)):\n",
    "            pred_mask=np.zeros((H,W,3),dtype=np.uint8)\n",
    "            #设置pred_mask为画布\n",
    "            runner.visualizer.set_image(pred_mask)\n",
    "            for color,class_idx in self.palette.items():\n",
    "                runner.visualizer.draw_binary_masks(\n",
    "                    pred==class_idx,#在哪些像素点画,pred是H*W的，但pred_mask是H*W*3的\n",
    "                    colors=[color],\n",
    "                    alphas=1.0\n",
    "                )\n",
    "            #转换为BGR\n",
    "            pred_mask=runner.visualizer.get_image()[...,::-1] #TODO 这个函数可以获得画完图之后的数组数据，值得借鉴\n",
    "            #存图，一张图对应三张结果图，存一个文件夹\n",
    "            save_dir=osp.join(runner.log_dir,'vis_data',str(idx))\n",
    "            os.makedirs(save_dir,exist_ok=True)\n",
    "            shutil.copyfile(img_path,osp.join(save_dir,osp.basename(img_path)))\n",
    "            shutil.copyfile(mask_path,osp.join(save_dir,osp.basename(mask_path)))\n",
    "\n",
    "            cv2.imwrite(osp.join(save_dir,f\"pred_{osp.basename(img_path)}\"),pred_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/14 02:04:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:39:04) [GCC 10.3.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 363155895\n",
      "    GPU 0,1: GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 10.2, V10.2.8\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.12.1+cu102\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu102\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.2\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 363155895\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/14 02:04:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/14 02:04:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisHook                         \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "08/14 02:04:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoU.\n",
      "08/14 02:04:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Dataset CamVid has no metainfo. ``dataset_meta`` in evaluator, metric and visualizer will be None.\n",
      "Loads checkpoint by local backend from path: /volume/opemmmlab/mmengine/work_dir/deeplabv3/epoch_10.pth\n",
      "08/14 02:04:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /volume/opemmmlab/mmengine/work_dir/deeplabv3/epoch_10.pth\n",
      "08/14 02:04:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Dataset CamVid has no metainfo. ``dataset_meta`` in visualizer will be None.\n",
      "08/14 02:04:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `resume_param_scheduler` is True but `self.param_schedulers` is None, so skip resuming parameter schedulers\n",
      "08/14 02:04:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - resumed epoch: 10, iter: 1230\n",
      "08/14 02:04:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][ 10/100]    eta: 0:04:26  time: 2.9557  data_time: 2.7750  memory: 1475  \n",
      "08/14 02:04:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][ 20/100]    eta: 0:02:06  time: 0.2150  data_time: 0.0376  memory: 1320  \n",
      "08/14 02:04:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][ 30/100]    eta: 0:01:19  time: 0.2155  data_time: 0.0372  memory: 1320  \n",
      "08/14 02:04:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][ 40/100]    eta: 0:00:54  time: 0.2160  data_time: 0.0376  memory: 1320  \n",
      "08/14 02:04:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][ 50/100]    eta: 0:00:38  time: 0.2159  data_time: 0.0375  memory: 1320  \n",
      "08/14 02:05:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][ 60/100]    eta: 0:00:26  time: 0.2168  data_time: 0.0382  memory: 1320  \n",
      "08/14 02:05:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][ 70/100]    eta: 0:00:18  time: 0.2173  data_time: 0.0389  memory: 1320  \n",
      "08/14 02:05:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][ 80/100]    eta: 0:00:11  time: 0.2182  data_time: 0.0395  memory: 1320  \n",
      "08/14 02:05:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][ 90/100]    eta: 0:00:05  time: 0.2165  data_time: 0.0380  memory: 1320  \n",
      "08/14 02:05:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][100/100]    eta: 0:00:00  time: 0.2159  data_time: 0.0371  memory: 1320  \n",
      "08/14 02:05:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][100/100]    iou: 0.9063  data_time: 0.3117  time: 0.4903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'iou': tensor(0.9063)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.optim import AmpOptimWrapper\n",
    "\n",
    "num_classes=32\n",
    "torch.cuda.empty_cache()\n",
    "runner=Runner(\n",
    "    model=MMDeeplabV3(num_classes=num_classes),\n",
    "    work_dir='./work_dir/deeplabv3',\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    train_cfg=dict(by_epoch=True,max_epochs=10,val_interval=10),\n",
    "    val_cfg = dict(),\n",
    "    #type后面可以是1).注册过的字符串，2).也可以直接是类，3).也可以不传入字典，直接传入对象\n",
    "    optim_wrapper=dict(type=AmpOptimWrapper,optimizer=dict(type=AdamW,lr=2e-4)),\n",
    "    val_evaluator=dict(type=IoU),\n",
    "    #自定义Hooks，以列表直接传入对象而非类的字典\n",
    "    custom_hooks=[SegVisHook(data_root='./data/CamVid/')],\n",
    "    #默认Hooks，传入类的字典\n",
    "    default_hooks=dict(checkpoint=dict(type='CheckpointHook', interval=10)),\n",
    "    resume=True,\n",
    "    load_from=\"/volume/opemmmlab/mmengine/work_dir/deeplabv3/epoch_10.pth\",\n",
    ")\n",
    "runner.val()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmyolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
