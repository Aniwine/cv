{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抽象数据接口 \\\n",
    "1.图像(img) \\\n",
    "2.数据样本(DataSample)：一个训练或测试样本的所有标注信息和预测信息 \\\n",
    "3.数据元素(xxxData)：单一类型的预测或标注，一般是指模型中子模块的输出\n",
    "\n",
    "注意：数据样本和数据元素并不是互斥关系，数据样本是对数据元素的高级封装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据样本和数据元素的基类：BaseDataElement \\\n",
    "包含两种数据类型，data和metainfo，data是可以通过key=value形式直接赋值的，metainfo必须显式指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mmyolo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#数据元素基类的创建\n",
    "from mmengine.structures import BaseDataElement \n",
    "import torch\n",
    "\n",
    "img_id=0\n",
    "H,W=640,640\n",
    "bboxes=torch.randn((5,4))\n",
    "scores=torch.randn((5,))\n",
    "\n",
    "#空\n",
    "data_sample=BaseDataElement()\n",
    "#直接赋值给data\n",
    "data_sample1=BaseDataElement(bboxes=bboxes,scores=scores)\n",
    "#显式赋值metainfo\n",
    "data_sample2=BaseDataElement(\n",
    "    bboxes=bboxes,\n",
    "    scores=scores,\n",
    "    metainfo=dict(img_id=img_id,img_shape=(H,W))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bboxes is in data_element1: True\n",
      "bboxes in data_element1 is same as bbox in data_element tensor(True)\n",
      "img_id in data_element1 is True\n",
      "bboxes is not in data_element2 True\n",
      "img_id in data_element2 is same as img_id in data_element True\n",
      "label in data_element2 is True\n"
     ]
    }
   ],
   "source": [
    "#BaseDataElement的new、clone方法\n",
    "\"\"\"\n",
    "用户可以使用 new() 方法基于已有的 BaseDataElement 创建一个具有相同 data 和 metainfo 的 \n",
    "BaseDataElement。用户也可以在调用 new 方法时传入新的 data 和 metainfo，例如 new(metainfo=xx) ，\n",
    "此时创建的 BaseDataElement 相较于已有的 BaseDataElement，data 完全一致 ，而 metainfo 则为新设置的内容。\n",
    "也可以直接使用 clone() 来获得一份深拷贝，clone() 函数的行为与 PyTorch 中 Tensor 的 clone() 参数保持一致\n",
    "\"\"\"\n",
    "data_element = BaseDataElement(\n",
    "    bboxes=torch.rand((5, 4)),\n",
    "    scores=torch.rand((5,)),\n",
    "    metainfo=dict(img_id=1, img_shape=(640, 640)))\n",
    "\n",
    "# 可以在创建新 `BaseDataElement` 时设置 metainfo 和 data，使得新的 BaseDataElement 有相同未被设置的数据\n",
    "data_element1 = data_element.new(metainfo=dict(img_id=2, img_shape=(320, 320)))\n",
    "print('bboxes is in data_element1:', 'bboxes' in data_element1) # True\n",
    "print('bboxes in data_element1 is same as bbox in data_element', (data_element1.bboxes == data_element.bboxes).all())\n",
    "print('img_id in data_element1 is', data_element1.img_id == 2) # True\n",
    "\n",
    "data_element2 = data_element.new(label=torch.rand(5,))\n",
    "print('bboxes is not in data_element2', 'bboxes' not in data_element2) # True\n",
    "print('img_id in data_element2 is same as img_id in data_element', data_element2.img_id == data_element.img_id)\n",
    "print('label in data_element2 is', 'label' in data_element2)\n",
    "\n",
    "# 也可以通过 `clone` 构建一个新的 object，新的 object 会拥有和 data_element 相同的 data 和 metainfo 内容以及状态。\n",
    "data_element2 = data_element1.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "属性的增加与查询 \\\n",
    "1. 增加data属性，像类属性一样，用.即可；增加metainfo属性，需要使用set_metainfo接口 \\\n",
    "2. 查询data属性，keys,values,items;查询metainfo属性，使用metainfo_keys,metainfo_values,metainfo_items,使用all_keys,all_values,all_items接口查询所有的属性，不区分类型 \\\n",
    "3. 通过get()接口像访问字典一样访问某个属性的值，也可直接像类属性一样查看(注意这个也是增加属性的方式) \\\n",
    "4. data和metainfo不能有相同的属性名 \\\n",
    "5. 不能使用名字索引取值、赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metainfo'keys are ['img_shape', 'img_id']\n",
      "metainfo'values are [(100, 100), 9]\n",
      "img_shape: (100, 100)\n",
      "img_id: 9\n",
      "通过类属性查看 img_id 和 img_shape\n",
      "img_id: 9\n",
      "img_shape: (100, 100)\n"
     ]
    }
   ],
   "source": [
    "from mmengine.structures import BaseDataElement\n",
    "data_element = BaseDataElement()\n",
    "# 通过 `set_metainfo`设置 data_element 的 metainfo 字段，\n",
    "# 同时 img_id 和 img_shape 成为 data_element 的属性\n",
    "data_element.set_metainfo(dict(img_id=9, img_shape=(100, 100)))\n",
    "# 查看 metainfo 的 key, value 和 item\n",
    "print(\"metainfo'keys are\", data_element.metainfo_keys())\n",
    "print(\"metainfo'values are\", data_element.metainfo_values())\n",
    "for k, v in data_element.metainfo_items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "print(\"通过类属性查看 img_id 和 img_shape\")\n",
    "print('img_id:', data_element.img_id)\n",
    "print('img_shape:', data_element.img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "属性的删改  \\\n",
    "data属性的修改和data属性的新增方式一样，通过类属性方式(.引用)   \\\n",
    "metainfo属性的修改，需要使用set_metainfo接口 \\\n",
    "删除接口，del和pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_id:9\n",
      "img_shape:(640, 640)\n",
      "scores:tensor([0.2028, 0.2644, 0.0398, 0.1335, 0.4261, 0.8572])\n",
      "bboxes:tensor([[0.5987, 0.0852, 0.6665, 0.7433],\n",
      "        [0.8427, 0.5409, 0.3495, 0.0052],\n",
      "        [0.6860, 0.0147, 0.5511, 0.5160],\n",
      "        [0.6471, 0.9110, 0.0569, 0.1992],\n",
      "        [0.4515, 0.5749, 0.6803, 0.0289],\n",
      "        [0.2259, 0.8861, 0.2789, 0.5278]])\n"
     ]
    }
   ],
   "source": [
    "from mmengine.structures import BaseDataElement\n",
    "import torch\n",
    "data_element=BaseDataElement(\n",
    "    bboxes=torch.rand((6,4)),\n",
    "    scores=torch.rand((6,)),\n",
    "    metainfo=dict(img_id=9, img_shape=(640, 640))\n",
    ")\n",
    "\n",
    "for k,v in data_element.all_items():\n",
    "    print(f\"{k}:{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: tensor([-0.2028, -0.2644, -0.0398, -0.1335, -0.4261, -0.8572])\n",
      "bboxes: tensor([[1.1974, 0.1704, 1.3329, 1.4867],\n",
      "        [1.6854, 1.0818, 0.6990, 0.0104],\n",
      "        [1.3720, 0.0294, 1.1021, 1.0320],\n",
      "        [1.2942, 1.8221, 0.1138, 0.3985],\n",
      "        [0.9031, 1.1498, 1.3606, 0.0578],\n",
      "        [0.4518, 1.7723, 0.5578, 1.0555]])\n",
      "scores: tensor([-0.2028, -0.2644, -0.0398, -0.1335, -0.4261, -0.8572])\n",
      "The keys in data is []\n"
     ]
    }
   ],
   "source": [
    "# 对 data 进行修改\n",
    "data_element.bboxes = data_element.bboxes * 2\n",
    "data_element.scores = data_element.scores * -1\n",
    "for k, v in data_element.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "# 删除 data 中的属性\n",
    "del data_element.bboxes\n",
    "for k, v in data_element.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "data_element.pop('scores', None)\n",
    "print('The keys in data is', data_element.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 1280)\n",
      "img_id: 10\n",
      "img_shape: (1280, 1280)\n",
      "img_id: 10\n",
      "The keys in metainfo is []\n"
     ]
    }
   ],
   "source": [
    "# 对 metainfo 进行修改\n",
    "data_element.set_metainfo(dict(img_shape = (1280, 1280), img_id=10))\n",
    "print(data_element.img_shape)  # (1280, 1280)\n",
    "for k, v in data_element.metainfo_items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "# 提供了便捷的属性删除和访问操作 pop\n",
    "del data_element.img_shape\n",
    "for k, v in data_element.metainfo_items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "data_element.pop('img_id')\n",
    "print('The keys in metainfo is', data_element.metainfo_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类张量操作 \\    \n",
    "用户可以像 torch.Tensor 那样对 BaseDataElement 的 data 进行状态转换，目前支持 cuda， cpu， to， numpy 等操作。 其中，to 函数拥有和 torch.Tensor.to() 相同的接口，使得用户可以灵活地将被封装的 tensor 进行状态转换。 注意： 这些接口只会处理类型为 np.array，torch.Tensor，或者数字的序列，其他属性的数据（如字符串）会被跳过处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_element_1's device is cuda:0\n",
      "cuda_element_2's device is cuda:0\n",
      "cpu_element_1 is on the device of cpu\n",
      "cpu_element_2 is on the device of cpu\n"
     ]
    }
   ],
   "source": [
    "from mmengine.structures import BaseDataElement\n",
    "import torch\n",
    "\n",
    "data_element=BaseDataElement(\n",
    "    bboxes=torch.rand((6,4)),\n",
    "    scores=torch.rand((6,)),\n",
    "    metainfo=dict(img_id=0, img_shape=(640, 640))\n",
    ")\n",
    "\n",
    "#转移到gpu上\n",
    "cuda_element_1=data_element.cuda()\n",
    "print(f\"cuda_element_1's device is {cuda_element_1.bboxes.device}\")\n",
    "cuda_element_2=data_element.to(torch.device('cuda:0'))\n",
    "print(f\"cuda_element_2's device is {cuda_element_2.bboxes.device}\")\n",
    "\n",
    "# 将所有 data 转移到 cpu 上\n",
    "cpu_element_1 = cuda_element_1.cpu()\n",
    "print('cpu_element_1 is on the device of', cpu_element_1.bboxes.device)  # cpu\n",
    "cpu_element_2 = cuda_element_2.to('cpu')\n",
    "print('cpu_element_2 is on the device of', cpu_element_2.bboxes.device)  # cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp16_instances's data type is torch.float16\n",
      "cuda_element_3 required grad is False\n",
      "The type of cpu_element_1 is convert to <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#将所有的data变成fp16\n",
    "fp16_instances=cuda_element_1.to(device=None,dtype=torch.float16,non_blocking=False, copy=False,\n",
    "    memory_format=torch.preserve_format)\n",
    "print(f\"fp16_instances's data type is {fp16_instances.bboxes.dtype}\")\n",
    "#阻断梯度\n",
    "cuda_element_3=cuda_element_1.detach()\n",
    "print(f'cuda_element_3 required grad is {cuda_element_3.bboxes.requires_grad}')\n",
    "#转移 data 到 numpy array\n",
    "np_instances = cpu_element_1.numpy()\n",
    "print('The type of cpu_element_1 is convert to', type(np_instances.bboxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "属性展示 \\\n",
    "BaseDataElement 还实现了 \\__repr__，因此，用户可以直接通过 print 函数看到其中的所有数据信息。 同时，为了便捷开发者 debug，BaseDataElement 中的属性都会添加进 \\__dict__ 中，方便用户在 IDE 界面可以直观看到 BaseDataElement 中的内容。 一个完整的属性展示如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BaseDataElement(\n",
      "\n",
      "    META INFORMATION\n",
      "    padding_shape: (4, 4, 3)\n",
      "    img_shape: (640, 640, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    labels: tensor([3, 9, 2, 6, 0, 3, 2, 5, 9, 0])\n",
      "    bboxes: tensor([[ 0.6133, -1.4811,  1.8712, -0.3347],\n",
      "                [-2.1329,  0.5925, -0.3979,  0.0459],\n",
      "                [ 0.2678, -0.2856, -1.5449, -0.2113],\n",
      "                [-0.4307, -1.1413,  0.2422,  0.1296],\n",
      "                [ 0.8319, -0.2335,  1.4273, -1.2889],\n",
      "                [ 2.9358, -0.7402, -0.6104,  0.5525],\n",
      "                [ 0.3033, -1.5639,  0.1427,  0.8960],\n",
      "                [-1.2516, -0.3869, -0.1031, -0.3760],\n",
      "                [ 0.6205,  0.1703,  1.1321,  0.1605],\n",
      "                [ 0.7103, -0.7690,  1.2041, -1.2740]])\n",
      ") at 0x7efd22545cf0>\n"
     ]
    }
   ],
   "source": [
    "img_info=dict(img_shape=(640, 640,3),padding_shape=(4,4,3))\n",
    "instances=BaseDataElement(metainfo=img_info)\n",
    "instances.bboxes=torch.randn(10,4)\n",
    "instances.labels=torch.randint(0,10,(10,))\n",
    "print(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据元素(xxData)\n",
    "1. InstanceData\n",
    "2. PixelData\n",
    "3. LabelData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 BaseDataElement 的基础上对 data 存储的数据做了限制，要求存储在 data 中的数据的长度一致。比如在目标检测中, 假设一张图像中有 N 个目标 (instance)，可以将图像的所有边界框 (bbox)，类别 (label) 等存储在 InstanceData 中, InstanceData 的 bbox 和 label 的长度相同 \n",
    "1. 对 InstanceData 中 data 所存储的数据进行了长度校验\n",
    "2. data 部分支持类字典访问和设置它的属性\n",
    "3. 支持基础索引，切片以及高级索引功能\n",
    "4. 支持具有相同的 key 但是不同的 InstanceData 进行拼接的功能。\n",
    "\n",
    "这些扩展功能除了支持基础的数据结构， 比如 torch.tensor, numpy.dnarray, list, str 和 tuple, 也可以是自定义的数据结构，只要自定义数据结构实现了 __len__, __getitem__ 和 cat 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of instances is 2\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The length of values 3 is not consistent with the length of this :obj:`InstanceData` 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe length of instances is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(instances)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m#len函数直接取用instances的data属性的长度\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#假如加入的data属性长度不等，则报断言错误\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m instances\u001b[39m.\u001b[39;49mbboxes\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mrandn(\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.10/site-packages/mmengine/structures/instance_data.py:152\u001b[0m, in \u001b[0;36mInstanceData.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(value,\n\u001b[1;32m    149\u001b[0m                   Sized), \u001b[39m'\u001b[39m\u001b[39mvalue must contain `__len__` attribute\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mThe length of \u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    153\u001b[0m                                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalues \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    154\u001b[0m                                     \u001b[39m'\u001b[39m\u001b[39mnot consistent with \u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    155\u001b[0m                                     \u001b[39m'\u001b[39m\u001b[39mthe length of this \u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    156\u001b[0m                                     \u001b[39m'\u001b[39m\u001b[39m:obj:`InstanceData` \u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    157\u001b[0m                                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    158\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(name, value)\n",
      "\u001b[0;31mAssertionError\u001b[0m: The length of values 3 is not consistent with the length of this :obj:`InstanceData` 2"
     ]
    }
   ],
   "source": [
    "#1.InstanceData 数据校验\n",
    "from mmengine.structures import InstanceData\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "img_data=dict(img_shape=(640, 640,3),padding_shape=(4,4,3))\n",
    "instances=InstanceData(metainfo=img_data)\n",
    "instances.bboxes=torch.randn(2,4)\n",
    "instances.det_labels=torch.LongTensor([2,3])\n",
    "instances.det_scores=torch.Tensor([0.9,0.8])\n",
    "\n",
    "print(f\"the length of instances is {len(instances)}\")#len函数直接取用instances的data属性的长度\n",
    "\n",
    "#假如加入的data属性长度不等，则报断言错误\n",
    "instances.bboxes=torch.randn(3,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.6656, 0.2982, 0.4252, 0.1886],\n",
      "                [0.7531, 0.9877, 0.2023, 0.7168]])\n",
      "    det_scores: tensor([0.8000, 0.7000])\n",
      "    det_labels: tensor([2, 3])\n",
      ") at 0x7f4a80453eb0>\n"
     ]
    }
   ],
   "source": [
    "#2.InstanceData是支持像字典一样按照字段名进行索引的\n",
    "img_meta = dict(img_shape=(800, 1196, 3), pad_shape=(800, 1216, 3))\n",
    "instance_data = InstanceData(metainfo=img_meta)\n",
    "instance_data[\"det_labels\"] = torch.LongTensor([2, 3])\n",
    "instance_data[\"det_scores\"] = torch.Tensor([0.8, 0.7])\n",
    "instance_data.bboxes = torch.rand((2, 4))\n",
    "print(instance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.7027, 0.4390, 0.1586, 0.8094],\n",
      "                [0.3566, 0.0361, 0.9358, 0.6374]])\n",
      "    det_scores: tensor([0.8000, 0.7000])\n",
      "    det_labels: tensor([2, 3])\n",
      ") at 0x7f4a7c16c4c0>\n"
     ]
    }
   ],
   "source": [
    "# 3.InstanceData 索引与切片\n",
    "img_meta = dict(img_shape=(800, 1196, 3), pad_shape=(800, 1216, 3))\n",
    "instance_data = InstanceData(metainfo=img_meta)\n",
    "instance_data.det_labels = torch.LongTensor([2, 3])\n",
    "instance_data.det_scores = torch.Tensor([0.8, 0.7])\n",
    "instance_data.bboxes = torch.rand((2, 4))\n",
    "print(instance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.7027, 0.4390, 0.1586, 0.8094]])\n",
      "    det_scores: tensor([0.8000])\n",
      "    det_labels: tensor([2])\n",
      ") at 0x7f4a7c16ce80>\n"
     ]
    }
   ],
   "source": [
    "#InstanceData支持按位置索引，但是取所有data属性，如下\n",
    "print(instance_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.7027, 0.4390, 0.1586, 0.8094]])\n",
      "    det_scores: tensor([0.8000])\n",
      "    det_labels: tensor([2])\n",
      ") at 0x7f4a80452b30>\n"
     ]
    }
   ],
   "source": [
    "#切片同理\n",
    "print(instance_data[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：在numpy、torch中索引是取出一个元素，其shape当缩减一，而切片是取出一个切片，其shape不变。 \\\n",
    "InstanceData的索引和切片都不会改变shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[[1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,2,3],[4,5,6]])\n",
    "print(a[0])\n",
    "print(a[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "b=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(b[0])\n",
    "print(b[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.3566, 0.0361, 0.9358, 0.6374],\n",
      "                [0.7027, 0.4390, 0.1586, 0.8094]])\n",
      "    det_scores: tensor([0.7000, 0.8000])\n",
      "    det_labels: tensor([3, 2])\n",
      ") at 0x7f49d784e290>\n"
     ]
    }
   ],
   "source": [
    "#列表索引\n",
    "sorted_results = instance_data[instance_data.det_scores.sort().indices]\n",
    "print(sorted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.7027, 0.4390, 0.1586, 0.8094]])\n",
      "    det_scores: tensor([0.8000])\n",
      "    det_labels: tensor([2])\n",
      ") at 0x7f49d784ee90>\n"
     ]
    }
   ],
   "source": [
    "#布尔索引\n",
    "filter_results=instance_data[instance_data.det_scores>0.75]\n",
    "print(filter_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([], size=(0, 4))\n",
      "    det_scores: tensor([])\n",
      "    det_labels: tensor([], dtype=torch.int64)\n",
      ") at 0x7f49d784e9b0>\n"
     ]
    }
   ],
   "source": [
    "#结果为空\n",
    "empty_results = instance_data[instance_data.det_scores > 1]\n",
    "print(empty_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of instance_data is 2\n",
      "The length of instance_data is 4\n",
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.1941, 0.2833, 0.1317, 0.0637],\n",
      "                [0.7264, 0.8688, 0.0104, 0.8151],\n",
      "                [0.1941, 0.2833, 0.1317, 0.0637],\n",
      "                [0.7264, 0.8688, 0.0104, 0.8151]])\n",
      "    det_scores: tensor([0.8000, 0.7000, 0.8000, 0.7000])\n",
      "    det_labels: tensor([2, 3, 2, 3])\n",
      ") at 0x7f49d784f070>\n"
     ]
    }
   ],
   "source": [
    "#具有相同key（包括metainfo和data属性）的InstanceData对象可以cat\n",
    "img_meta = dict(img_shape=(800, 1196, 3), pad_shape=(800, 1216, 3))\n",
    "instance_data = InstanceData(metainfo=img_meta)\n",
    "instance_data.det_labels = torch.LongTensor([2, 3])\n",
    "instance_data.det_scores = torch.Tensor([0.8, 0.7])\n",
    "instance_data.bboxes = torch.rand((2, 4))\n",
    "print('The length of instance_data is', len(instance_data))\n",
    "cat_results = InstanceData.cat([instance_data, instance_data])\n",
    "print('The length of instance_data is', len(cat_results))\n",
    "print(cat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义数据结构，需要实现__len__,__getitem__,cat静态方法\n",
    "import itertools\n",
    "\n",
    "class TmpObject:\n",
    "    def __init__(self, tmp) -> None:\n",
    "        assert isinstance(tmp, list)\n",
    "        self.tmp = tmp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tmp)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if type(item) == int:\n",
    "            if item >= len(self) or item < -len(self):  # type:ignore\n",
    "                raise IndexError(f'Index {item} out of range!')\n",
    "            else:\n",
    "                # keep the dimension\n",
    "                item = slice(item, None, len(self))\n",
    "        return TmpObject(self.tmp[item])\n",
    "\n",
    "    @staticmethod\n",
    "    def cat(tmp_objs):\n",
    "        assert all(isinstance(results, TmpObject) for results in tmp_objs)\n",
    "        if len(tmp_objs) == 1:\n",
    "            return tmp_objs[0]\n",
    "        tmp_list = [tmp_obj.tmp for tmp_obj in tmp_objs]\n",
    "        tmp_list = list(itertools.chain(*tmp_list))\n",
    "        new_data = TmpObject(tmp_list)\n",
    "        return new_data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#这段代码有三个地方值得注意\n",
    "#1. slice方法  (start,stop,step)返回slice对象，可以用于切片\n",
    "#写成slice(idx,None,len(nums))的形式，可以取出nums中idx位置的元素，且保持shape不变\n",
    "nums=list(range(10))\n",
    "s=slice(1,None,len(nums))\n",
    "nums[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.all方法，判断传入可迭代对象的每一个元素是否为真\n",
    "#这里主要是说明本来是应该写成all((isinstance(results, TmpObject) for results in tmp_objs))的形式\n",
    "#因为for循环单独写不行，应该写成元组生成器(xxx for ...)的形式，但是这里省略括号，直接放入all()方法的括号里也行\n",
    "#这应该是一种写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6, 7, 8]] [[1, 2, 3, 4], [5, 6, 7, 8]]\n",
      "[[1, 2, 3, 4], [5, 6, 7, 8], [1, 2, 3, 4], [5, 6, 7, 8]]\n"
     ]
    }
   ],
   "source": [
    "#3.itertools.chain方法：将多个可迭代对象整合为一个可迭代对象，并保持shape不变\n",
    "#比如多维的列表，这里的*a为两个2维数组，整合之后仍是2维数组，也就是整合发生在最外层\n",
    "#用这个即可实现任意可迭代对象的cat方法\n",
    "import itertools\n",
    "a=[[[1, 2, 3, 4], [5, 6, 7, 8]],[[1, 2, 3, 4], [5, 6, 7, 8]]]\n",
    "print(*a)\n",
    "b=itertools.chain(*a)\n",
    "print(list(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.9587, 0.0455, 0.6518, 0.6603],\n",
      "                [0.0439, 0.6812, 0.9202, 0.5651]])\n",
      "    det_scores: tensor([0.8000, 0.7000])\n",
      "    polygons: [[1, 2, 3, 4], [5, 6, 7, 8]]\n",
      "    det_labels: tensor([2, 3])\n",
      ") at 0x7f49d78283a0>\n"
     ]
    }
   ],
   "source": [
    "img_meta = dict(img_shape=(800, 1196, 3), pad_shape=(800, 1216, 3))\n",
    "instance_data = InstanceData(metainfo=img_meta)\n",
    "instance_data.det_labels = torch.LongTensor([2, 3])\n",
    "instance_data[\"det_scores\"] = torch.Tensor([0.8, 0.7])\n",
    "instance_data.bboxes = torch.rand((2, 4))\n",
    "instance_data.polygons = TmpObject([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "#print函数会调用instance_data中每一个属性的__repr__方法,可以看到这里直接显示的tmp值，而不是整个对象\n",
    "print(instance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.9587, 0.0455, 0.6518, 0.6603]])\n",
      "    det_scores: tensor([0.8000])\n",
      "    polygons: [[1, 2, 3, 4]]\n",
      "    det_labels: tensor([2])\n",
      ") at 0x7f4a7c16c5e0>\n"
     ]
    }
   ],
   "source": [
    "# 高级索引\n",
    "print(instance_data[instance_data.det_scores > 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InstanceData(\n",
      "\n",
      "    META INFORMATION\n",
      "    img_shape: (800, 1196, 3)\n",
      "    pad_shape: (800, 1216, 3)\n",
      "\n",
      "    DATA FIELDS\n",
      "    bboxes: tensor([[0.9587, 0.0455, 0.6518, 0.6603],\n",
      "                [0.0439, 0.6812, 0.9202, 0.5651],\n",
      "                [0.9587, 0.0455, 0.6518, 0.6603],\n",
      "                [0.0439, 0.6812, 0.9202, 0.5651]])\n",
      "    det_scores: tensor([0.8000, 0.7000, 0.8000, 0.7000])\n",
      "    polygons: [[1, 2, 3, 4], [5, 6, 7, 8], [1, 2, 3, 4], [5, 6, 7, 8]]\n",
      "    det_labels: tensor([2, 3, 2, 3])\n",
      ") at 0x7f49d7829c90>\n"
     ]
    }
   ],
   "source": [
    "# 拼接\n",
    "print(InstanceData.cat([instance_data, instance_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PixelData \\\n",
    "在BaseDataElement基础上对data属性做了两点约束： \n",
    "1. 所有 data 内的数据均为 3 维，并且顺序为 (通道，高，宽) \n",
    "2. 所有在 data 内的数据要有相同的长和宽\n",
    "且具有以下扩展：\\\n",
    "1.对PixelData 中 data 所存储的数据进行了尺寸的校验 \\\n",
    "2支持对 data 部分的数据对实例进行空间维度的索引和切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of pixel_data is (20, 40)\n",
      "The shape of pixel_data is torch.Size([1, 20, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/miniconda3/lib/python3.10/site-packages/mmengine/structures/pixel_data.py:83: UserWarning: The shape of value will convert from torch.Size([20, 40]) to torch.Size([1, 20, 40])\n",
      "  warnings.warn('The shape of value will convert from '\n"
     ]
    }
   ],
   "source": [
    "from mmengine.structures import PixelData\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "metainfo=dict(\n",
    "    img_id=random.randint(0, 100),\n",
    "    img_shape=(random.randint(400,600),random.randint(400,600))\n",
    ")\n",
    "image=np.random.randint(0,255,(4,20,40))\n",
    "featmap=np.random.randint(0,255,(10,20,40))\n",
    "\n",
    "pixel_data=PixelData(image=image,\n",
    "                     featmap=featmap,\n",
    "                     metainfo=metainfo)\n",
    "\n",
    "print('The shape of pixel_data is', pixel_data.shape)\n",
    "# set\n",
    "pixel_data.map3 = torch.randint(0, 255, (20, 40))\n",
    "print('The shape of pixel_data is', pixel_data.map3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The height and width of values (20, 30) is not consistent with the shape of this :obj:`PixelData` (20, 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pixel_data\u001b[39m.\u001b[39;49mmap2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m30\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[39m# AssertionError: the height and width of values (20, 30) is not consistent with the length of this :obj:`PixelData` (20, 40)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.10/site-packages/mmengine/structures/pixel_data.py:71\u001b[0m, in \u001b[0;36mPixelData.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(value, (torch\u001b[39m.\u001b[39mTensor, np\u001b[39m.\u001b[39mndarray)), \\\n\u001b[1;32m     67\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCan not set \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m, only support\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m     68\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m(torch\u001b[39m.\u001b[39mTensor,\u001b[39m \u001b[39mnp\u001b[39m.\u001b[39mndarray)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, (\n\u001b[1;32m     72\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThe height and width of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalues \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:])\u001b[39m}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     74\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnot consistent with \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     75\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mthe shape of this \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     76\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m:obj:`PixelData` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[39massert\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39min\u001b[39;00m [\n\u001b[1;32m     79\u001b[0m     \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m\n\u001b[1;32m     80\u001b[0m ], \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe dim of value must be 2 or 3, but got \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: The height and width of values (20, 30) is not consistent with the shape of this :obj:`PixelData` (20, 40)"
     ]
    }
   ],
   "source": [
    "pixel_data.map2 = torch.randint(0, 255, (3, 20, 30))\n",
    "# AssertionError: the height and width of values (20, 30) is not consistent with the length of this :obj:`PixelData` (20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The dim of value must be 2 or 3, but got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pixel_data\u001b[39m.\u001b[39;49mmap2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, (\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m40\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[39m# AssertionError: The dim of value must be 2 or 3, but got 4\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.10/site-packages/mmengine/structures/pixel_data.py:78\u001b[0m, in \u001b[0;36mPixelData.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape:\n\u001b[1;32m     71\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, (\n\u001b[1;32m     72\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThe height and width of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalues \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:])\u001b[39m}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m:obj:`PixelData` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m \u001b[39massert\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39min\u001b[39;00m [\n\u001b[1;32m     79\u001b[0m     \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m\n\u001b[1;32m     80\u001b[0m ], \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe dim of value must be 2 or 3, but got \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m     82\u001b[0m     value \u001b[39m=\u001b[39m value[\u001b[39mNone\u001b[39;00m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: The dim of value must be 2 or 3, but got 4"
     ]
    }
   ],
   "source": [
    "pixel_data.map2 = torch.randint(0, 255, (1, 3, 20, 40))\n",
    "# AssertionError: The dim of value must be 2 or 3, but got 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of pixel_data is (20, 40)\n"
     ]
    }
   ],
   "source": [
    "#空间维度索引\n",
    "#PixelData支持对data部分的数据实例进行空间维度的索引和切片，只需传入长度\n",
    "metainfo=dict(\n",
    "    img_id=random.randint(0, 100),\n",
    "    img_shape=(random.randint(400,600),random.randint(400,600))\n",
    ")\n",
    "image=np.random.randint(0,255,(4,20,40))\n",
    "featmap=np.random.randint(0,255,(10,20,40))\n",
    "\n",
    "pixel_data=PixelData(image=image,\n",
    "                     featmap=featmap,\n",
    "                     metainfo=metainfo)\n",
    "\n",
    "#可以看到pixel_data.shape是只有长和宽的\n",
    "print(\"The shape of pixel_data is\",pixel_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of index_data is  (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#索引\n",
    "#索引返回的也是一个PixelData对象，所以其shape也只有长和宽\n",
    "index_data=pixel_data[10,20]\n",
    "print(\"The shape of index_data is \",index_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of slice_data is (10, 20)\n"
     ]
    }
   ],
   "source": [
    "#切片\n",
    "#切片同理\n",
    "slice_data=pixel_data[10:20,20:40]\n",
    "print(\"The shape of slice_data is\",slice_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelData \\\n",
    "LabelData主要用来封装标签数据，如场景分类标签，文字识别标签等。LabelData没有对data做任何限制，只提供了两个额外功能：onehot和index的转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.structures import LabelData\n",
    "import torch\n",
    "\n",
    "item=torch.tensor([1],dtype=torch.int64)\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 is convert to  tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]) is convert to  tensor([1])\n"
     ]
    }
   ],
   "source": [
    "onehot=LabelData.label_to_onehot(label=item,num_classes=num_classes)\n",
    "print(f\"{num_classes} is convert to \",onehot)\n",
    "\n",
    "index=LabelData.onehot_to_label(onehot=onehot)\n",
    "print(f\"{onehot} is convert to \",index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据样本(xxxDataSample) \\\n",
    "对数据元素的高级封装，用于保存图像级别的标注信息（包括各种标注，如实例分割，检测，语义分割，类别等）\\\n",
    "以MMDet下游库为例，定义DetDataSample，其定义了7个字段: \\\n",
    "括号内为其数据类型\n",
    "\n",
    "- 标注信息：\n",
    "    gt_instance(InstanceData)：实例标注信息，包括实例的类别、边界框等\n",
    "    gt_panoptic_seg(PixelData):全景分割的标注信息\n",
    "    gt_semantic_seg(PixelData):语义分割的标注信息\n",
    "- 预测结果：\n",
    "    pred_instance(InstanceData):实例预测结果，包括实例的类别、边界框等\n",
    "    pred_panoptic_seg(PixelData):全景分割的预测信息\n",
    "    pred_semantic_seg(PixelData):语义分割的预测信息\n",
    "- 中间结果：\n",
    "    proposal(InstanceData):主要为二阶段中RPN的预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#property的setter和deleter方法分别设置了被装饰函数的赋值和删除的自定义操作\n",
    "\n",
    "from mmengine.structures import BaseDataElement\n",
    "import torch\n",
    "\n",
    "class DetDataSample(BaseDataElement):\n",
    "\n",
    "    # 标注\n",
    "    @property\n",
    "    def gt_instances(self) -> InstanceData:\n",
    "        return self._gt_instances\n",
    "\n",
    "    #设置属性时 类型的约束\n",
    "    @gt_instances.setter\n",
    "    def gt_instances(self, value: InstanceData):\n",
    "        self.set_field(value, '_gt_instances', dtype=InstanceData)\n",
    "\n",
    "    @gt_instances.deleter\n",
    "    def gt_instances(self):\n",
    "        del self._gt_instances\n",
    "\n",
    "    @property\n",
    "    def gt_panoptic_seg(self) -> PixelData:\n",
    "        return self._gt_panoptic_seg\n",
    "\n",
    "    @gt_panoptic_seg.setter\n",
    "    def gt_panoptic_seg(self, value: PixelData):\n",
    "        self.set_field(value, '_gt_panoptic_seg', dtype=PixelData)\n",
    "\n",
    "    @gt_panoptic_seg.deleter\n",
    "    def gt_panoptic_seg(self):\n",
    "        del self._gt_panoptic_seg\n",
    "\n",
    "    @property\n",
    "    def gt_sem_seg(self) -> PixelData:\n",
    "        return self._gt_sem_seg\n",
    "\n",
    "    @gt_sem_seg.setter\n",
    "    def gt_sem_seg(self, value: PixelData):\n",
    "        self.set_field(value, '_gt_sem_seg', dtype=PixelData)\n",
    "\n",
    "    @gt_sem_seg.deleter\n",
    "    def gt_sem_seg(self):\n",
    "        del self._gt_sem_seg\n",
    "\n",
    "    # 预测\n",
    "    @property\n",
    "    def pred_instances(self) -> InstanceData:\n",
    "        return self._pred_instances\n",
    "\n",
    "    @pred_instances.setter\n",
    "    def pred_instances(self, value: InstanceData):\n",
    "        self.set_field(value, '_pred_instances', dtype=InstanceData)\n",
    "\n",
    "    @pred_instances.deleter\n",
    "    def pred_instances(self):\n",
    "        del self._pred_instances\n",
    "\n",
    "    @property\n",
    "    def pred_panoptic_seg(self) -> PixelData:\n",
    "        return self._pred_panoptic_seg\n",
    "\n",
    "    @pred_panoptic_seg.setter\n",
    "    def pred_panoptic_seg(self, value: PixelData):\n",
    "        self.set_field(value, '_pred_panoptic_seg', dtype=PixelData)\n",
    "\n",
    "    @pred_panoptic_seg.deleter\n",
    "    def pred_panoptic_seg(self):\n",
    "        del self._pred_panoptic_seg\n",
    "\n",
    "    # 中间结果\n",
    "    @property\n",
    "    def pred_sem_seg(self) -> PixelData:\n",
    "        return self._pred_sem_seg\n",
    "\n",
    "    @pred_sem_seg.setter\n",
    "    def pred_sem_seg(self, value: PixelData):\n",
    "        self.set_field(value, '_pred_sem_seg', dtype=PixelData)\n",
    "\n",
    "    @pred_sem_seg.deleter\n",
    "    def pred_sem_seg(self):\n",
    "        del self._pred_sem_seg\n",
    "\n",
    "    @property\n",
    "    def proposals(self) -> InstanceData:\n",
    "        return self._proposals\n",
    "\n",
    "    @proposals.setter\n",
    "    def proposals(self, value: InstanceData):\n",
    "        self.set_field(value, '_proposals', dtype=InstanceData)\n",
    "\n",
    "    @proposals.deleter\n",
    "    def proposals(self):\n",
    "        del self._proposals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类型约束 \\\n",
    "上述每一个属性的赋值操作都设置了类型约束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接口简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不同组件输入的参数不一定相同，在mmdet3.x版本中都简化为img,data_sample的形式，不同组件按照需求按名字索引对应值即可。\n",
    "from mmdet.models import BaseDetector\n",
    "class SingleStageDetector(BaseDetector):\n",
    "    ...\n",
    "\n",
    "    def forward_train(self,\n",
    "                      img,\n",
    "                      data_samples):\n",
    "        pass\n",
    "\n",
    "class SingleStageInstanceSegmentor(BaseDetector):\n",
    "    ...\n",
    "\n",
    "    def forward_train(self,\n",
    "                      img,\n",
    "                      data_samples):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mmyolo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "940063cc59a0c2d21681d7ac95c121a8937264e558270ac3e68c34e5b2668d53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
